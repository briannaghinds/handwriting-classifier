{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imported libraries\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,  # load train set\n",
    "    transform=ToTensor(),\n",
    "    download=True  # download the dataset\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    download=True  # download the dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train and test data in batches, shuffle it, etc\n",
    "loaders = {\n",
    "    \"train\" : DataLoader(train_data, batch_size=100,shuffle=True, num_workers=1),\n",
    "    \"test\" : DataLoader(test_data, batch_size=100, shuffle=True, num_workers=1)  \n",
    "}\n",
    "\n",
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model architecture\n",
    "# the neural network structure\n",
    "\n",
    "class CNN(nn.Module):  # inherits from the nn.Module\n",
    "    def __init__(self):\n",
    "        # call the super class\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)  # takes 1 channel in and 10 out\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)  # takes 10 channels in and 20 out\n",
    "        self.conv2_dropout = nn.Dropout2d()  # dropout layer is a regularization layer, it will randomly (based on a probability) deactivate certain network nodes\n",
    "        self.fcl = nn.Linear(320, 50)  # takes 320 in and 50 out\n",
    "        self.fcl2 = nn.Linear(50, 10)  # takes 50 in and 10 out (IT HAS TO TAKE 10 OUT (0-9) = 10 digits)\n",
    "\n",
    "    def forward(self, x):  # this will define the activations\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_dropout(self.conv2(x)), 2))\n",
    "\n",
    "        # reshape/flatten the data\n",
    "        x = x.view(-1, 320)\n",
    "\n",
    "        x = F.relu(self.fcl(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fcl2(x)\n",
    "\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize and train the data\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# define a loss functin\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# define the training process\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    for batch_i, (data, target) in enumerate(loaders[\"train\"]):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        if batch_i % 20 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_i * len(data)}/{len(loaders['train'].dataset)} ({100. * batch_i / len(loaders['train'].dataset):.0f}%)]\\t{loss.item():.6f}\")\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0 \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders[\"test\"]:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders[\"test\"].dataset)\n",
    "    print(f\"\\nTest Set: Average Loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders['test'].dataset)} ({100. * correct / len(loaders['test'].dataset):.0f}%\\n)\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call functions\n",
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "\n",
    "torch.save(model, \"models/handwritten_GNN_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = test_data[0]\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "WHAT IM THINKING: get the image, turn it into a tensor then feed it into the model\n",
    "and print out the CNNs prediction\n",
    "\"\"\"\n",
    "# get the image and turn it into gray scale\n",
    "img_path = \"handwritting/image0.png\"  # image path here\n",
    "img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (28,28))\n",
    "\n",
    "print(img.shape)  # (530, 800)  -> (28, 28)\n",
    "\n",
    "# turn to a tensor\n",
    "data = torch.from_numpy(img).unsqueeze(0).float() / 255.0\n",
    "# print(data.min().item(), data.max().item())\n",
    "\n",
    "data = torch.reshape(data, (1, 28, 28))\n",
    "# print(data)\n",
    "# print(data.shape)\n",
    "\n",
    "\n",
    "output = model(data)\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "print(f\"Prediction: {prediction}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
